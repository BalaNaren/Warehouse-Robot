{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "m7As7qh4navx"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from gym import envs\n",
        "from IPython.display import display, clear_output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from time import sleep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "J0CJ4tDeaNja"
      },
      "outputs": [],
      "source": [
        "env = gym.make('Taxi-v3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNlV-YvdnlOH",
        "outputId": "e7d67ba2-f250-4677-b073-c2bfa9ddbd48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial state: 193\n",
            "Time: Discrete(6)\n",
            "Speed: Discrete(6)\n",
            "State Space Discrete(500)\n",
            "- DOWN: Discrete(500)\n",
            "- LEFT: Discrete(500)\n",
            "- RIGHT: Discrete(500)\n",
            "Action Space Discrete(6)\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the scene states of the warehouse robot\n",
        "state = env.reset()\n",
        "\n",
        "print(f\"Initial state: {state}\")\n",
        "# Checkout observable features of the warehouse robot interacting with its environment\n",
        "#print(\"State space:\", env.observation_space)\n",
        "print(\"Time:\", env.action_space)\n",
        "print(\"Speed:\", env.action_space)\n",
        "\n",
        "# Exploring the state observation space\n",
        "\n",
        "print(\"State Space {}\".format(env.observation_space))\n",
        "\n",
        "print(\"- DOWN:\", env.observation_space)\n",
        "\n",
        "print(\"- LEFT:\", env.observation_space)\n",
        "\n",
        "print(\"- RIGHT:\", env.observation_space)\n",
        "\n",
        "## Exploring action space\n",
        "\n",
        "print(\"Action Space {}\".format(env.action_space))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVCYl1XuGrdn",
        "outputId": "eb3f516c-0eb7-4c64-d64d-015b9bcd9c8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.00000000e+00  0.00000000e+00  1.00000000e+01  0.00000000e+00]\n",
            " [ 0.00000000e+00  3.00000000e+00  9.99314767e+00  2.61679781e-01]\n",
            " [ 0.00000000e+00  5.00000000e+00  9.98097349e+00  4.35778714e-01]\n",
            " ...\n",
            " [ 1.80000000e+02  1.75000000e+02 -1.90265095e-02 -4.35778714e-01]\n",
            " [ 1.80000000e+02  1.78000000e+02 -3.04586490e-03 -1.74497484e-01]\n",
            " [ 1.80000000e+02  1.80000000e+02  0.00000000e+00 -6.12323400e-16]]\n"
          ]
        }
      ],
      "source": [
        "## Reading from Dataset\n",
        "iff = pd.read_csv('robot.csv', header=None)\n",
        "view_matrix = iff.values\n",
        "\n",
        "print(view_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "koepKE1CMoeU"
      },
      "outputs": [],
      "source": [
        "env.render()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTqOwRPzMo4W",
        "outputId": "057d0105-5284-4894-8d51-10940386f0bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tabulate-rewards: -33\n"
          ]
        }
      ],
      "source": [
        "# Check out movements\n",
        "maxrewards=0\n",
        "obs= env.reset()\n",
        "env.render()\n",
        "for i in range(6):\n",
        "    action = env.action_space.sample()\n",
        "    obs, reward, done, info = env.step(action)\n",
        "    maxrewards += reward\n",
        "    env.render()\n",
        "#List down rewards for every action\n",
        "print(\"Tabulate-rewards: %r\" % maxrewards)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24s-95BiPFE4",
        "outputId": "769a4c5a-6039-4cfb-9375-6e228364010b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: [(1.0, 226, -1, False)],\n",
              " 1: [(1.0, 26, -1, False)],\n",
              " 2: [(1.0, 126, -1, False)],\n",
              " 3: [(1.0, 106, -1, False)],\n",
              " 4: [(1.0, 126, -10, False)],\n",
              " 5: [(1.0, 126, -10, False)]}"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check out random space\n",
        "\n",
        "env.P[126]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTaLVE2FP4La",
        "outputId": "f2748a72-30a3-4670-c06f-43fa179121ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scene 50 Max Reward: -200\n",
            "Scene 100 Max Reward: -200\n",
            "Scene 150 Max Reward: -120\n",
            "Scene 200 Max Reward: -200\n",
            "Scene 250 Max Reward: -64\n",
            "Scene 300 Max Reward: -81\n",
            "Scene 350 Max Reward: -9\n",
            "Scene 400 Max Reward: -37\n",
            "Scene 450 Max Reward: -67\n",
            "Scene 500 Max Reward: -18\n",
            "Scene 550 Max Reward: -24\n",
            "Scene 600 Max Reward: -29\n",
            "Scene 650 Max Reward: -73\n",
            "Scene 700 Max Reward: 13\n",
            "Scene 750 Max Reward: -37\n",
            "Scene 800 Max Reward: 11\n",
            "Scene 850 Max Reward: -46\n",
            "Scene 900 Max Reward: 4\n",
            "Scene 950 Max Reward: -89\n",
            "Scene 1000 Max Reward: 7\n",
            "Scene 1050 Max Reward: 9\n",
            "Scene 1100 Max Reward: 2\n",
            "Scene 1150 Max Reward: 9\n",
            "Scene 1200 Max Reward: -2\n",
            "Scene 1250 Max Reward: 7\n",
            "Scene 1300 Max Reward: 7\n",
            "Scene 1350 Max Reward: 6\n",
            "Scene 1400 Max Reward: 8\n",
            "Scene 1450 Max Reward: -2\n",
            "Scene 1500 Max Reward: -13\n",
            "Scene 1550 Max Reward: 4\n",
            "Scene 1600 Max Reward: -3\n",
            "Scene 1650 Max Reward: -12\n",
            "Scene 1700 Max Reward: 9\n",
            "Scene 1750 Max Reward: 5\n",
            "Scene 1800 Max Reward: 3\n",
            "Scene 1850 Max Reward: -8\n",
            "Scene 1900 Max Reward: 4\n",
            "Scene 1950 Max Reward: 2\n",
            "Scene 2000 Max Reward: 6\n",
            "Scene 2050 Max Reward: 6\n",
            "Scene 2100 Max Reward: 6\n"
          ]
        }
      ],
      "source": [
        "# Qlearning\n",
        "\n",
        "learn_rate = 0.2\n",
        "qtable = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "discount = 0.4\n",
        "\n",
        "for scene in range(1,2134):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    maxrewards = 0\n",
        "\n",
        "    while done != True:\n",
        "        action = np.argmax(qtable[state])\n",
        "        state_new, reward, done, info = env.step(action)\n",
        "        qtable[state,action] += learn_rate * (reward + discount * np.max(qtable[state_new,:]) - qtable[state,action])\n",
        "        maxrewards = maxrewards + reward\n",
        "        state = state_new\n",
        "    if scene % 50 == 0:\n",
        "        print('Scene {} Max Reward: {}'.format(scene,maxrewards))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTSr6L7GUs73",
        "outputId": "6469ded9-2628-407e-abd8-d537a91a0de7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "****************************************************\n",
            "STARTING \n",
            "Number of steps 0\n",
            "Number of steps 1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "env.reset()\n",
        "\n",
        "state = env.reset()\n",
        "step = 0\n",
        "done = False\n",
        "print(\"****************************************************\")\n",
        "print(\"STARTING \")\n",
        "env.render()\n",
        "for step in range(maxrewards):\n",
        "\n",
        "    # Take the action (index) that have the maximum expected future reward given that state\n",
        "    action = np.argmax(qtable[state,:])\n",
        "\n",
        "    new_state, reward, done, info = env.step(action)\n",
        "\n",
        "\n",
        "    env.render()\n",
        "\n",
        "    # We print the current step.\n",
        "    print(\"Number of steps\", step)\n",
        "    if done:\n",
        "      break\n",
        "    state = new_state\n",
        "env.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml-refresher",
      "language": "python",
      "name": "ml-refresher"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
